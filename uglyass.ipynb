{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import re\n",
    "import io\n",
    "from utilities.features_csv import to_csv\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import csv \n",
    "docs = {}\n",
    "labels = {}\n",
    "#I only work if you run me in the same folder as the actual text files \n",
    "\n",
    "with open('training_labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            id = int(row[1])\n",
    "            score= float(row[2])\n",
    "            labels[id]=score\n",
    "            line_count += 1\n",
    "i = 0\n",
    "for root, dirs, files in os.walk(\"corpus/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            id = re.sub(\"[^0-9]\", \"\", file)\n",
    "            id = int(id) \n",
    "            path_file = os.path.join(root,file)\n",
    "            curdir = path_file\n",
    "            file = open(curdir, 'r', errors='ignore')\n",
    "            i+=1\n",
    "            text = file.read()\n",
    "            docs[id] = text\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 6)\n"
     ]
    }
   ],
   "source": [
    "#auto features here \n",
    "import os \n",
    "import numpy as np \n",
    "import os\n",
    "import re \n",
    "import csv \n",
    "import math \n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd \n",
    "train_x,train_y = [],[]\n",
    "for k in labels:\n",
    "    try:\n",
    "        if docs[k] and labels[k]:\n",
    "            train_x.append(docs[k]) \n",
    "            train_y.append(labels[k])\n",
    "    except KeyError:\n",
    "        pass\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def vectorize(txt):\n",
    "    count_vect = CountVectorizer(stop_words=stopwords.words('english'),max_features = 6,strip_accents ='ascii')\n",
    "    #print(count_vect.get_feature_names)\n",
    "    vects = count_vect.fit_transform(txt)\n",
    "    print(vects.shape) \n",
    "    return count_vect\n",
    "\n",
    "from sklearn.preprocessing import normalize \n",
    "def normalize_vect(v):\n",
    "    return normalize(v)\n",
    "    \n",
    "v = vectorize(train_x)\n",
    "imp_words = v.get_feature_names()\n",
    "id_ct = {}\n",
    "for id in docs:\n",
    "    id_ct[id] = [0]*len(imp_words)\n",
    "for id in id_ct:\n",
    "    txt = docs[id] \n",
    "    for x in range(len(imp_words)):\n",
    "        word = imp_words[x]\n",
    "        if word in txt:\n",
    "            id_ct[id][x] +=1\n",
    "dat = pd.DataFrame(data = id_ct)\n",
    "dat = dat.transpose()\n",
    "dat.columns = imp_words\n",
    "dat['iD'] = dat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iD</th>\n",
       "      <th>minor</th>\n",
       "      <th>geo-location</th>\n",
       "      <th>contact_email</th>\n",
       "      <th>vendors</th>\n",
       "      <th>sell_personal</th>\n",
       "      <th>share_personal</th>\n",
       "      <th>cookies</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>Score</th>\n",
       "      <th>data</th>\n",
       "      <th>information</th>\n",
       "      <th>may</th>\n",
       "      <th>personal</th>\n",
       "      <th>privacy</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.245872</td>\n",
       "      <td>183.114146</td>\n",
       "      <td>-4.42</td>\n",
       "      <td>9.08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.621470</td>\n",
       "      <td>141.546392</td>\n",
       "      <td>37.79</td>\n",
       "      <td>7.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.272983</td>\n",
       "      <td>133.162162</td>\n",
       "      <td>46.30</td>\n",
       "      <td>6.61</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.408232</td>\n",
       "      <td>171.012987</td>\n",
       "      <td>7.88</td>\n",
       "      <td>8.48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.172602</td>\n",
       "      <td>197.930605</td>\n",
       "      <td>-10.99</td>\n",
       "      <td>9.82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.849897</td>\n",
       "      <td>92.117647</td>\n",
       "      <td>87.96</td>\n",
       "      <td>4.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.693526</td>\n",
       "      <td>129.228758</td>\n",
       "      <td>50.29</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92.805165</td>\n",
       "      <td>227.010582</td>\n",
       "      <td>-48.97</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.038524</td>\n",
       "      <td>160.092896</td>\n",
       "      <td>18.96</td>\n",
       "      <td>7.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.908131</td>\n",
       "      <td>102.258824</td>\n",
       "      <td>77.66</td>\n",
       "      <td>5.07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iD  minor  geo-location  contact_email  vendors  sell_personal  \\\n",
       "0  20481      1             0              0        1              0   \n",
       "1  20484      0             0              1        0              0   \n",
       "2    854      0             0              0        0              0   \n",
       "3  20490      1             0              1        0              0   \n",
       "4  20493      0             0              0        0              0   \n",
       "5  22701      0             0              0        0              0   \n",
       "6  22360      0             0              0        0              0   \n",
       "7  20500      0             0              0        0              0   \n",
       "8    516      0             1              0        0              0   \n",
       "9  20506      0             0              0        0              0   \n",
       "\n",
       "   share_personal  cookies  fog_index  avg_sentence_length  \\\n",
       "0               0        0  75.245872           183.114146   \n",
       "1               1        1  58.621470           141.546392   \n",
       "2               0        0  55.272983           133.162162   \n",
       "3               0        0  70.408232           171.012987   \n",
       "4               0        0  81.172602           197.930605   \n",
       "5               0        0  38.849897            92.117647   \n",
       "6               0        0  53.693526           129.228758   \n",
       "7               0        1  92.805165           227.010582   \n",
       "8               0        1  66.038524           160.092896   \n",
       "9               0        0  42.908131           102.258824   \n",
       "\n",
       "   flesch_reading_ease  dale_chall_readability_score  Score  data  \\\n",
       "0                -4.42                          9.08    3.0     1   \n",
       "1                37.79                          7.02    3.0     1   \n",
       "2                46.30                          6.61    2.0     1   \n",
       "3                 7.88                          8.48    3.0     1   \n",
       "4               -10.99                          9.82    2.0     1   \n",
       "5                87.96                          4.57    1.0     1   \n",
       "6                50.29                          6.41    1.0     0   \n",
       "7               -48.97                         11.26    2.0     1   \n",
       "8                18.96                          7.94    2.0     1   \n",
       "9                77.66                          5.07    2.0     0   \n",
       "\n",
       "   information  may  personal  privacy  use  \n",
       "0            1    1         1        1    1  \n",
       "1            1    1         1        1    1  \n",
       "2            1    1         1        1    1  \n",
       "3            1    1         1        1    1  \n",
       "4            1    1         0        1    1  \n",
       "5            1    1         0        1    1  \n",
       "6            1    1         0        1    1  \n",
       "7            1    1         1        1    1  \n",
       "8            1    1         1        1    1  \n",
       "9            1    1         1        1    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sike.csv\")\n",
    "frames = [data,dat]\n",
    "data =  data.merge(dat,how='left',on='iD')\n",
    "display(data.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minor</th>\n",
       "      <th>contact_email</th>\n",
       "      <th>vendors</th>\n",
       "      <th>share_personal</th>\n",
       "      <th>cookies</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>may</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.245872</td>\n",
       "      <td>183.114146</td>\n",
       "      <td>-4.42</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.621470</td>\n",
       "      <td>141.546392</td>\n",
       "      <td>37.79</td>\n",
       "      <td>7.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.272983</td>\n",
       "      <td>133.162162</td>\n",
       "      <td>46.30</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.408232</td>\n",
       "      <td>171.012987</td>\n",
       "      <td>7.88</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.172602</td>\n",
       "      <td>197.930605</td>\n",
       "      <td>-10.99</td>\n",
       "      <td>9.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minor  contact_email  vendors  share_personal  cookies  fog_index  \\\n",
       "0      1              0        1               0        0  75.245872   \n",
       "1      0              1        0               1        1  58.621470   \n",
       "2      0              0        0               0        0  55.272983   \n",
       "3      1              1        0               0        0  70.408232   \n",
       "4      0              0        0               0        0  81.172602   \n",
       "\n",
       "   avg_sentence_length  flesch_reading_ease  dale_chall_readability_score  may  \n",
       "0           183.114146                -4.42                          9.08    1  \n",
       "1           141.546392                37.79                          7.02    1  \n",
       "2           133.162162                46.30                          6.61    1  \n",
       "3           171.012987                 7.88                          8.48    1  \n",
       "4           197.930605               -10.99                          9.82    1  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spliting labels and features\n",
    "scores = data['Score']\n",
    "features_raw = data.drop(['Score', 'iD'] , axis = 1)\n",
    "features_raw = features_raw.drop([\"sell_personal\",'geo-location'],axis=1)\n",
    "# features_raw = features_raw.drop(['geo-location'],axis=1)\n",
    "features_raw = features_raw.drop(['data','information','use','privacy','personal'],axis=1)\n",
    "features_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minor</th>\n",
       "      <th>contact_email</th>\n",
       "      <th>vendors</th>\n",
       "      <th>share_personal</th>\n",
       "      <th>cookies</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>may</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.660721</td>\n",
       "      <td>0.660803</td>\n",
       "      <td>0.335780</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418250</td>\n",
       "      <td>0.418325</td>\n",
       "      <td>0.575923</td>\n",
       "      <td>0.417647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369411</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.624339</td>\n",
       "      <td>0.369412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590163</td>\n",
       "      <td>0.590213</td>\n",
       "      <td>0.405758</td>\n",
       "      <td>0.589412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747164</td>\n",
       "      <td>0.747232</td>\n",
       "      <td>0.298401</td>\n",
       "      <td>0.747059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129876</td>\n",
       "      <td>0.129992</td>\n",
       "      <td>0.861353</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minor  contact_email  vendors  share_personal  cookies  fog_index  \\\n",
       "0      1              0        1               0        0   0.660721   \n",
       "1      0              1        0               1        1   0.418250   \n",
       "2      0              0        0               0        0   0.369411   \n",
       "3      1              1        0               0        0   0.590163   \n",
       "4      0              0        0               0        0   0.747164   \n",
       "5      0              0        0               0        0   0.129876   \n",
       "\n",
       "   avg_sentence_length  flesch_reading_ease  dale_chall_readability_score  may  \n",
       "0             0.660803             0.335780                      0.660000    1  \n",
       "1             0.418325             0.575923                      0.417647    1  \n",
       "2             0.369417             0.624339                      0.369412    1  \n",
       "3             0.590213             0.405758                      0.589412    1  \n",
       "4             0.747232             0.298401                      0.747059    1  \n",
       "5             0.129992             0.861353                      0.129412    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['fog_index', 'avg_sentence_length', 'flesch_reading_ease', 'dale_chall_readability_score']\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_raw)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_raw[numerical])\n",
    "\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 347 samples.\n",
      "Testing set has 87 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_log_minmax_transform, \n",
    "                                                    scores, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8774389997983464"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=15, max_depth=None,random_state=1, criterion=\"entropy\")\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "predictions = forest.predict(X_test)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for x in range(1,200):\n",
    "#     for y in range(1,200):\n",
    "#         for z in range(1,200):\n",
    "#             forest  = RandomForestClassifier(n_estimators=y, max_depth=z,random_state=x, criterion=\"gini\")\n",
    "#             forest.fit(X_train, y_train)\n",
    "#             predi = forest.predict(X_test)\n",
    "#             ans = f1_score(y_test, predi, average = 'macro')\n",
    "#             if ans > .92:\n",
    "#                 print (\"random_state: \" + str(x))\n",
    "#                 print (\"n_estimators: \" + str(y))\n",
    "#                 print(\"max_depth: \" + str(z))\n",
    "#                 print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1193548387096774"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt  = DecisionTreeClassifier(random_state = 47, criterion='gini', splitter = 'random', max_depth=14)\n",
    "dt.fit(X_train, y_train)\n",
    "f1_score(y_test, predi, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-2e5f3315be73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mpredi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.952\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"random_state: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1047\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "for x in range(0,100):\n",
    "    for y in range(1,100):\n",
    "        for z in range(1,11):\n",
    "            dt  = DecisionTreeClassifier( presort = True,random_state = x, criterion='gini', splitter = 'random', max_depth=y, max_features = z)\n",
    "            dt.fit(X_train, y_train)\n",
    "            predi = dt.predict(X_test)\n",
    "            ans = f1_score(y_test, predi, average = 'macro')\n",
    "            if ans > .952:\n",
    "                print (\"random_state: \" + str(x))\n",
    "                print (\"n_estimators: \" + str(y))\n",
    "                print(\"max_features: \" + str(z))\n",
    "                print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8079267710846658"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "from sklearn.metrics import f1_score \n",
    "f1_score(y_test, predictions, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# dt  = DecisionTreeClassifier( random_state = 1, criterion='gini', splitter = 'random', max_depth=20)\n",
    "# dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# #good params base_estimator = dt,n_estimators=5, learning_rate=1.0, algorithm='SAMME.R', random_state=1)\n",
    "\n",
    "# #good params w nltk stop words model = AdaBoostClassifier(base_estimator = dt,n_estimators=14, learning_rate=.2, algorithm='SAMME.R', random_state=1)\n",
    "# ada = AdaBoostClassifier(random_state = 21,base_estimator = dt,n_estimators=13, learning_rate=.2, algorithm='SAMME.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(0,300):\n",
    "#     for y in range(1,220):\n",
    "#             ada = AdaBoostClassifier(random_state = x,base_estimator = ET,n_estimators=y, learning_rate=.8, algorithm='SAMME.R')\n",
    "#             ada.fit(X_train, y_train)\n",
    "#             predi = ada.predict(X_test)\n",
    "#             ans = f1_score(y_test, predi, average = 'macro')\n",
    "#             if ans > .93:\n",
    "#                 print (\"random_state: \" + str(x))\n",
    "#                 print (\"n_estimators: \" + str(y))\n",
    "#                 print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada.fit(X_train, y_train)\n",
    "# predi = ada.predict(X_test)\n",
    "# f1_score(y_test, predi, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(0,100):\n",
    "#     for y in range(1,100):\n",
    "#             ada = AdaBoostClassifier(random_state = x,base_estimator = dt,n_estimators=y, learning_rate=1.5, algorithm='SAMME.R')\n",
    "#             ada.fit(X_train, y_train)\n",
    "#             predi = ada.predict(X_test)\n",
    "#             ans = np.mean(predi == y_test)\n",
    "#             if ans > .94:\n",
    "#                 print (\"random_state: \" + str(x))\n",
    "#                 print (\"n_estimators: \" + str(y))\n",
    "#                 print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8079267710846658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "ET = ExtraTreesClassifier(n_estimators = 35, random_state = 0, criterion='entropy')\n",
    "ET.fit(X_train, y_train)\n",
    "predi = ET.predict(X_test)\n",
    "ans = f1_score(y_test, predictions, average = 'macro')\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.755% (5.146%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "X = features_log_minmax_transform\n",
    "y = scores\n",
    "num_folds = 5\n",
    "num_instances = len(X)\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "model = ET\n",
    "results = model_selection.cross_val_score(model, X, y, cv=skf)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.73      0.81        15\n",
      "           2       0.78      0.86      0.82        37\n",
      "           3       0.77      0.77      0.77        22\n",
      "           4       0.67      0.60      0.63        10\n",
      "           5       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        87\n",
      "   macro avg       0.83      0.79      0.81        87\n",
      "weighted avg       0.80      0.79      0.79        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['1', '2', '3', '4', '5']\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# for x in range(0,200):\n",
    "#     for y in range(1,200):\n",
    "#             ET = ExtraTreesClassifier(n_estimators = y, random_state = x, criterion='entropy')\n",
    "#             ET.fit(X_train, y_train)\n",
    "#             predi = ET.predict(X_test)\n",
    "#             ans = f1_score(y_test, predictions, average = 'macro')\n",
    "#             if ans > .952:\n",
    "#                 print (\"random_state: \" + str(x))\n",
    "#                 print (\"n_estimators: \" + str(y))\n",
    "#                 print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02504848, 0.02431843, 0.1642951 , 0.05268337, 0.00274841,\n",
       "       0.04196103, 0.08697089, 0.16526299, 0.17214442, 0.14396289,\n",
       "       0.11215423, 0.00844975])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  3  0  0  0]\n",
      " [ 1 33  3  0  0]\n",
      " [ 0  5 17  0  0]\n",
      " [ 0  1  5  4  0]\n",
      " [ 0  0  0  0  3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test)\n",
    "# # specify parameters via map\n",
    "# param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'multi:softmax'}\n",
    "# xgb_param = model.get_xgb_params()\n",
    "# xgb_param['num_class'] = 6\n",
    "# num_round = 2\n",
    "# bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "params = {\n",
    "        'min_child_weight': [1, 2, 3],\n",
    "        'gamma': [0.25, 0.5, 1, 1.5, 2, 3,5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.4,0.6, 0.8, 1.0],\n",
    "        'max_depth': list(range(10,1000))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  23 out of  25 | elapsed:    3.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done  25 out of  25 | elapsed:    3.6s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.09, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=6,\n",
       "          param_distributions={'min_child_weight': [1, 2, 3], 'gamma': [0.25, 0.5, 1, 1.5, 2, 3, 5], 'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.4, 0.6, 0.8, 1.0], 'max_depth': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,...980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1001, refit=True,\n",
       "          return_train_score='warn', scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(learning_rate =.09, n_estimators=50, objective= 'multi:softprob')\n",
    "\n",
    "\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='f1_macro', n_jobs=6, cv=5, verbose=3, random_state=1001 )\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "# predi = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5990097419372664"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_\n",
    "# random_search.best_params_\n",
    "#f1_score(y_test, predi, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
