{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regular = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "text = 'dwadwa ericktorres@gmail.edu dwadwa'\n",
    "if (re.search(regular, text)):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add('OBAMA', None, nlp(u\"Barack Obama\"))\n",
    "doc = nlp(u\"Barack Obama lifts America one last time in emotional farewell\")\n",
    "matches = matcher(doc)\n",
    "print(matches[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trade', 'portion', 'part', 'sharing', 'merchandising', 'partake', 'selling', 'share', 'marketing', 'market', 'sale', 'seller', 'percentage', 'deal', 'sell'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "#are we also using words like sharing?\n",
    "# words = ['sell', 'selling', 'sold', 'sale']\n",
    "words = ['sell', 'selling', 'sold', 'sale', 'share','sharing']\n",
    "list_of_words = []\n",
    "for word in words:\n",
    "    syn = wordnet.synsets(word)[0]\n",
    "    lemmas = syn.lemmas()\n",
    "    for lemma in lemmas:\n",
    "        list_of_words.append(lemma.name())\n",
    "        related_forms = lemma.derivationally_related_forms()\n",
    "        for form in related_forms:\n",
    "            list_of_words.append(form.synset().name().split('.')[0])\n",
    "print(set(list_of_words))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sell'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'merchandising'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[1].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marketing'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[2].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'selling'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selling', 'merchandising', 'marketing']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lemma.name() for lemma in syn.lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deal'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[0].derivationally_related_forms()[1].synset().name().split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don't\n"
     ]
    }
   ],
   "source": [
    "print('don\\'t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We/PRP <--nsubj-- sell/VBP\n",
      "sell/VBP <--ROOT-- sell/VBP\n",
      "personal/JJ <--amod-- data/NNS\n",
      "data/NNS <--dobj-- sell/VBP\n",
      "./. <--punct-- sell/VBP\n",
      "We/PRP <--nsubj-- are/VBP\n",
      "are/VBP <--ROOT-- are/VBP\n",
      "awesome/JJ <--acomp-- are/VBP\n",
      "./. <--punct-- are/VBP\n",
      "We/PRP <--nsubj-- sell/VBP\n",
      "sell/VBP <--ROOT-- sell/VBP\n",
      "data/NNS <--dobj-- sell/VBP\n",
      "!/. <--punct-- sell/VBP\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('We sell personal data. We are awesome. We sell data!')\n",
    "for token in doc:\n",
    "    print(\"{0}/{1} <--{2}-- {3}/{4}\".format(\n",
    "        token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "def break_sentences(text):\n",
    "    nlp = spacy.load('en')\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.string.strip() for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "def word_count(text):\n",
    "    sentences = break_sentences(text)\n",
    "    words = 0\n",
    "    for sentence in sentences:\n",
    "        words += len([token for token in sentence])\n",
    "    return words\n",
    "\n",
    "print(word_count(\"Erick Torres is cool. I am also cool. Are you cool?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_callback(callbacks):\n",
    "    callbacks()\n",
    "\n",
    "def erick():\n",
    "    dictio = {}\n",
    "    def callback():\n",
    "        dictio[\"prince\"] = \"sucks\"\n",
    "    call_callback(callback)\n",
    "    return dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 'sucks'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = set(('foo', 'bar', 'baz', 'foo', 'qux'))\n",
    "if 'bazz' in x:\n",
    "    print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
