{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import re\n",
    "import io\n",
    "from utilities.features_csv import to_csv\n",
    "# from utilities.feature_engineering import *\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import csv \n",
    "docs = {}\n",
    "labels = {}\n",
    "#I only work if you run me in the same folder as the actual text files \n",
    "\n",
    "with open('training_labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            id = int(row[1])\n",
    "            score= float(row[2])\n",
    "            labels[id]=score\n",
    "            line_count += 1\n",
    "i = 0\n",
    "for root, dirs, files in os.walk(\"corpus/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            id = re.sub(\"[^0-9]\", \"\", file)\n",
    "            id = int(id) \n",
    "            path_file = os.path.join(root,file)\n",
    "            curdir = path_file\n",
    "            file = open(curdir, 'r', errors='ignore')\n",
    "            i+=1\n",
    "            text = file.read()\n",
    "            docs[id] = text\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to_csv(docs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iD</th>\n",
       "      <th>minor</th>\n",
       "      <th>geo-location</th>\n",
       "      <th>contact_email</th>\n",
       "      <th>vendors</th>\n",
       "      <th>sell_personal</th>\n",
       "      <th>share_personal</th>\n",
       "      <th>Cookies</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.245659</td>\n",
       "      <td>183.114146</td>\n",
       "      <td>-4.42</td>\n",
       "      <td>9.08</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.618557</td>\n",
       "      <td>141.546392</td>\n",
       "      <td>37.79</td>\n",
       "      <td>7.02</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.264865</td>\n",
       "      <td>133.162162</td>\n",
       "      <td>46.30</td>\n",
       "      <td>6.60</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.405195</td>\n",
       "      <td>171.012987</td>\n",
       "      <td>7.88</td>\n",
       "      <td>8.48</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.172242</td>\n",
       "      <td>197.930605</td>\n",
       "      <td>-10.99</td>\n",
       "      <td>9.82</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.731507</td>\n",
       "      <td>114.328767</td>\n",
       "      <td>65.41</td>\n",
       "      <td>5.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.727168</td>\n",
       "      <td>119.317919</td>\n",
       "      <td>60.35</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92.804233</td>\n",
       "      <td>227.010582</td>\n",
       "      <td>-48.97</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.037158</td>\n",
       "      <td>160.092896</td>\n",
       "      <td>18.96</td>\n",
       "      <td>7.94</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.903529</td>\n",
       "      <td>102.258824</td>\n",
       "      <td>77.66</td>\n",
       "      <td>5.07</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iD  minor  geo-location  contact_email  vendors  sell_personal  \\\n",
       "0  20481      1             0              0        1              0   \n",
       "1  20484      0             0              1        0              0   \n",
       "2    854      0             0              0        0              0   \n",
       "3  20490      1             0              1        0              0   \n",
       "4  20493      0             0              0        0              0   \n",
       "5    173      0             0              1        0              0   \n",
       "6  11096      0             0              1        0              0   \n",
       "7  20500      0             0              0        0              0   \n",
       "8    516      0             1              0        0              0   \n",
       "9  20506      0             0              0        0              0   \n",
       "\n",
       "   share_personal  Cookies  fog_index  avg_sentence_length  \\\n",
       "0               0        0  75.245659           183.114146   \n",
       "1               1        1  58.618557           141.546392   \n",
       "2               0        0  55.264865           133.162162   \n",
       "3               0        1  70.405195           171.012987   \n",
       "4               0        0  81.172242           197.930605   \n",
       "5               0        1  47.731507           114.328767   \n",
       "6               0        0  49.727168           119.317919   \n",
       "7               0        1  92.804233           227.010582   \n",
       "8               0        1  66.037158           160.092896   \n",
       "9               0        0  42.903529           102.258824   \n",
       "\n",
       "   flesch_reading_ease  dale_chall_readability_score  Score  \n",
       "0                -4.42                          9.08    3.0  \n",
       "1                37.79                          7.02    3.0  \n",
       "2                46.30                          6.60    2.0  \n",
       "3                 7.88                          8.48    3.0  \n",
       "4               -10.99                          9.82    2.0  \n",
       "5                65.41                          5.67    3.0  \n",
       "6                60.35                          5.92    2.0  \n",
       "7               -48.97                         11.26    2.0  \n",
       "8                18.96                          7.94    2.0  \n",
       "9                77.66                          5.07    2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"final.csv\")\n",
    "display(data.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spliting labels and features\n",
    "scores = data['Score']\n",
    "features_raw = data.drop(['Score', 'iD'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minor</th>\n",
       "      <th>geo-location</th>\n",
       "      <th>contact_email</th>\n",
       "      <th>vendors</th>\n",
       "      <th>sell_personal</th>\n",
       "      <th>share_personal</th>\n",
       "      <th>Cookies</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.660803</td>\n",
       "      <td>0.660803</td>\n",
       "      <td>0.332320</td>\n",
       "      <td>0.660400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418325</td>\n",
       "      <td>0.418325</td>\n",
       "      <td>0.569989</td>\n",
       "      <td>0.418331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.617905</td>\n",
       "      <td>0.368978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590213</td>\n",
       "      <td>0.590213</td>\n",
       "      <td>0.401577</td>\n",
       "      <td>0.589894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747232</td>\n",
       "      <td>0.747232</td>\n",
       "      <td>0.295327</td>\n",
       "      <td>0.747356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minor  geo-location  contact_email  vendors  sell_personal  share_personal  \\\n",
       "0      1             0              0        1              0               0   \n",
       "1      0             0              1        0              0               1   \n",
       "2      0             0              0        0              0               0   \n",
       "3      1             0              1        0              0               0   \n",
       "4      0             0              0        0              0               0   \n",
       "\n",
       "   Cookies  fog_index  avg_sentence_length  flesch_reading_ease  \\\n",
       "0        0   0.660803             0.660803             0.332320   \n",
       "1        1   0.418325             0.418325             0.569989   \n",
       "2        0   0.369417             0.369417             0.617905   \n",
       "3        1   0.590213             0.590213             0.401577   \n",
       "4        0   0.747232             0.747232             0.295327   \n",
       "\n",
       "   dale_chall_readability_score  \n",
       "0                      0.660400  \n",
       "1                      0.418331  \n",
       "2                      0.368978  \n",
       "3                      0.589894  \n",
       "4                      0.747356  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['fog_index', 'avg_sentence_length', 'flesch_reading_ease', 'dale_chall_readability_score']\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_raw)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_raw[numerical])\n",
    "\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 347 samples.\n",
      "Testing set has 87 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_log_minmax_transform, \n",
    "                                                    scores, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505747126436781"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=15, max_depth=20,random_state=1, criterion=\"entropy\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import fbeta_score, accuracy_score\n",
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "# forest_final = RandomForestClassifier(random_state=4)\n",
    "# parameters = {'bootstrap': [True, False],\n",
    "#  'max_depth': [11, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#  'max_features': ['auto', 'sqrt'],\n",
    "#  'min_samples_leaf': [1, 2, 4],\n",
    "#  'min_samples_split': [2, 5, 10],\n",
    "#  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "#  'criterion':[\"entropy\", \"gini\"]}\n",
    "\n",
    "# scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "# grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# best_predictions = best_clf.predict(X_test)\n",
    "# f1_score(y_test, best_predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=14,\n",
       "            splitter='random')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt  = DecisionTreeClassifier( random_state = 14, criterion='gini', splitter = 'random', max_depth=15)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for x in range(0,100):\n",
    "#     for y in range(1,100):\n",
    "#             dt  = DecisionTreeClassifier( random_state = x, criterion='entropy', splitter = 'random', max_depth=y)\n",
    "#             dt.fit(X_train, y_train)\n",
    "#             predi = dt.predict(X_test)\n",
    "#             ans = np.mean(predi == y_test)\n",
    "#             if ans > .92:\n",
    "#                 print (\"random_state: \" + str(x))\n",
    "#                 print (\"n_estimators: \" + str(y))\n",
    "#                 print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=14,\n",
       "            splitter='random')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9195402298850575"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# dt  = DecisionTreeClassifier( random_state = 1, criterion='gini', splitter = 'random', max_depth=20)\n",
    "# dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#good params base_estimator = dt,n_estimators=5, learning_rate=1.0, algorithm='SAMME.R', random_state=1)\n",
    "\n",
    "#good params w nltk stop words model = AdaBoostClassifier(base_estimator = dt,n_estimators=14, learning_rate=.2, algorithm='SAMME.R', random_state=1)\n",
    "ada = AdaBoostClassifier(random_state = 1,base_estimator = dt,n_estimators=22, learning_rate=.6, algorithm='SAMME.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=14,\n",
       "            splitter='random'),\n",
       "          learning_rate=0.6, n_estimators=22, random_state=1)"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predi = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620689655172413"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predi == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-783-2939860d6da1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mada\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mada\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mpredi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mada\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \"\"\"\n\u001b[0;32m    472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    524\u001b[0m         estimator_weight = (-1. * self.learning_rate\n\u001b[0;32m    525\u001b[0m                                 * (((n_classes - 1.) / n_classes) *\n\u001b[1;32m--> 526\u001b[1;33m                                    inner1d(y_coding, np.log(y_predict_proba))))\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# Only boost the weights if it will fit again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(0,100):\n",
    "    for y in range(1,100):\n",
    "            ada = AdaBoostClassifier(random_state = x,base_estimator = dt,n_estimators=y, learning_rate=1.5, algorithm='SAMME.R')\n",
    "            ada.fit(X_train, y_train)\n",
    "            predi = ada.predict(X_test)\n",
    "            ans = np.mean(predi == y_test)\n",
    "            if ans > .92:\n",
    "                print (\"random_state: \" + str(x))\n",
    "                print (\"n_estimators: \" + str(y))\n",
    "                print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9310344827586207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "ET = ExtraTreesClassifier(n_estimators = 1, random_state = 14, criterion='entropy')\n",
    "ET.fit(X_train, y_train)\n",
    "predi = ET.predict(X_test)\n",
    "ans = np.mean(predi == y_test)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03468525, 0.01681815, 0.16091817, 0.09633278, 0.0040461 ,\n",
       "       0.05148408, 0.08528065, 0.154515  , 0.12417392, 0.12225961,\n",
       "       0.1494863 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ET.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# for x in range(0,100):\n",
    "#     for y in range(1,100):\n",
    "#             forest = ExtraTreesClassifier(n_estimators = y, random_state = x, criterion='gini')\n",
    "#             forest.fit(X_train, y_train)\n",
    "#             predi = forest.predict(X_test)\n",
    "#             ans = np.mean(predi == y_test)\n",
    "#             if ans > .93:\n",
    "#                 print (\"random_state: \" + str(x))\n",
    "#                 print (\"n_estimators: \" + str(y))\n",
    "#                 print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  1  0  0  0]\n",
      " [ 1 43  0  0  0]\n",
      " [ 0  3 18  0  0]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
